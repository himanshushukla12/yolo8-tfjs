{"ast":null,"code":"import*as tf from\"@tensorflow/tfjs\";import{renderBoxes}from\"./renderBox\";import labels from\"./labels.json\";const numClass=labels.length;/**\r\n * Preprocess image / frame before forwarded into the model\r\n * @param {HTMLVideoElement|HTMLImageElement} source\r\n * @param {Number} modelWidth\r\n * @param {Number} modelHeight\r\n * @returns input tensor, xRatio and yRatio\r\n */const preprocess=(source,modelWidth,modelHeight)=>{let xRatio,yRatio;// ratios for boxes\nconst input=tf.tidy(()=>{const img=tf.browser.fromPixels(source);// padding image to square => [n, m] to [n, n], n > m\nconst[h,w]=img.shape.slice(0,2);// get source width and height\nconst maxSize=Math.max(w,h);// get max size\nconst imgPadded=img.pad([[0,maxSize-h],// padding y [bottom only]\n[0,maxSize-w],// padding x [right only]\n[0,0]]);xRatio=maxSize/w;// update xRatio\nyRatio=maxSize/h;// update yRatio\nreturn tf.image.resizeBilinear(imgPadded,[modelWidth,modelHeight])// resize frame\n.div(255.0)// normalize\n.expandDims(0);// add batch\n});return[input,xRatio,yRatio];};/**\r\n * Function run inference and do detection from source.\r\n * @param {HTMLImageElement|HTMLVideoElement} source\r\n * @param {tf.GraphModel} model loaded YOLOv8 tensorflow.js model\r\n * @param {HTMLCanvasElement} canvasRef canvas reference\r\n * @param {VoidFunction} callback function to run after detection process\r\n */export const detect=async function(source,model,canvasRef){let callback=arguments.length>3&&arguments[3]!==undefined?arguments[3]:()=>{};const[modelWidth,modelHeight]=model.inputShape.slice(1,3);// get model width and height\ntf.engine().startScope();// start scoping tf engine\nconst[input,xRatio,yRatio]=preprocess(source,modelWidth,modelHeight);// preprocess image\nconst res=model.net.execute(input);// inference model\nconst transRes=res.transpose([0,2,1]);// transpose result [b, det, n] => [b, n, det]\nconst boxes=tf.tidy(()=>{const w=transRes.slice([0,0,2],[-1,-1,1]);// get width\nconst h=transRes.slice([0,0,3],[-1,-1,1]);// get height\nconst x1=tf.sub(transRes.slice([0,0,0],[-1,-1,1]),tf.div(w,2));// x1\nconst y1=tf.sub(transRes.slice([0,0,1],[-1,-1,1]),tf.div(h,2));// y1\nreturn tf.concat([y1,x1,tf.add(y1,h),//y2\ntf.add(x1,w)//x2\n],2).squeeze();});// process boxes [y1, x1, y2, x2]\nconst[scores,classes]=tf.tidy(()=>{// class scores\nconst rawScores=transRes.slice([0,0,4],[-1,-1,numClass]).squeeze(0);// #6 only squeeze axis 0 to handle only 1 class models\nreturn[rawScores.max(1),rawScores.argMax(1)];});// get max scores and classes index\nconst nms=await tf.image.nonMaxSuppressionAsync(boxes,scores,500,0.45,0.2);// NMS to filter boxes\nconst boxes_data=boxes.gather(nms,0).dataSync();// indexing boxes by nms index\nconst scores_data=scores.gather(nms,0).dataSync();// indexing scores by nms index\nconst classes_data=classes.gather(nms,0).dataSync();// indexing classes by nms index\nrenderBoxes(canvasRef,boxes_data,scores_data,classes_data,[xRatio,yRatio]);// render boxes\ntf.dispose([res,transRes,boxes,scores,classes,nms]);// clear memory\ncallback();tf.engine().endScope();// end of scoping\n};/**\r\n * Function to detect video from every source.\r\n * @param {HTMLVideoElement} vidSource video source\r\n * @param {tf.GraphModel} model loaded YOLOv8 tensorflow.js model\r\n * @param {HTMLCanvasElement} canvasRef canvas reference\r\n */export const detectVideo=(vidSource,model,canvasRef)=>{/**\r\n   * Function to detect every frame from video\r\n   */const detectFrame=async()=>{if(vidSource.videoWidth===0&&vidSource.srcObject===null){const ctx=canvasRef.getContext(\"2d\");ctx.clearRect(0,0,ctx.canvas.width,ctx.canvas.height);// clean canvas\nreturn;// handle if source is closed\n}detect(vidSource,model,canvasRef,()=>{requestAnimationFrame(detectFrame);// get another frame\n});};detectFrame();// initialize to detect every frame\n};","map":{"version":3,"names":["tf","renderBoxes","labels","numClass","length","preprocess","source","modelWidth","modelHeight","xRatio","yRatio","input","tidy","img","browser","fromPixels","h","w","shape","slice","maxSize","Math","max","imgPadded","pad","image","resizeBilinear","div","expandDims","detect","model","canvasRef","callback","arguments","undefined","inputShape","engine","startScope","res","net","execute","transRes","transpose","boxes","x1","sub","y1","concat","add","squeeze","scores","classes","rawScores","argMax","nms","nonMaxSuppressionAsync","boxes_data","gather","dataSync","scores_data","classes_data","dispose","endScope","detectVideo","vidSource","detectFrame","videoWidth","srcObject","ctx","getContext","clearRect","canvas","width","height","requestAnimationFrame"],"sources":["E:/office work/hositngYOLOgithub/yolov8-tfjs/src/utils/detect.js"],"sourcesContent":["import * as tf from \"@tensorflow/tfjs\";\r\nimport { renderBoxes } from \"./renderBox\";\r\nimport labels from \"./labels.json\";\r\n\r\nconst numClass = labels.length;\r\n\r\n/**\r\n * Preprocess image / frame before forwarded into the model\r\n * @param {HTMLVideoElement|HTMLImageElement} source\r\n * @param {Number} modelWidth\r\n * @param {Number} modelHeight\r\n * @returns input tensor, xRatio and yRatio\r\n */\r\nconst preprocess = (source, modelWidth, modelHeight) => {\r\n  let xRatio, yRatio; // ratios for boxes\r\n\r\n  const input = tf.tidy(() => {\r\n    const img = tf.browser.fromPixels(source);\r\n\r\n    // padding image to square => [n, m] to [n, n], n > m\r\n    const [h, w] = img.shape.slice(0, 2); // get source width and height\r\n    const maxSize = Math.max(w, h); // get max size\r\n    const imgPadded = img.pad([\r\n      [0, maxSize - h], // padding y [bottom only]\r\n      [0, maxSize - w], // padding x [right only]\r\n      [0, 0],\r\n    ]);\r\n\r\n    xRatio = maxSize / w; // update xRatio\r\n    yRatio = maxSize / h; // update yRatio\r\n\r\n    return tf.image\r\n      .resizeBilinear(imgPadded, [modelWidth, modelHeight]) // resize frame\r\n      .div(255.0) // normalize\r\n      .expandDims(0); // add batch\r\n  });\r\n\r\n  return [input, xRatio, yRatio];\r\n};\r\n\r\n/**\r\n * Function run inference and do detection from source.\r\n * @param {HTMLImageElement|HTMLVideoElement} source\r\n * @param {tf.GraphModel} model loaded YOLOv8 tensorflow.js model\r\n * @param {HTMLCanvasElement} canvasRef canvas reference\r\n * @param {VoidFunction} callback function to run after detection process\r\n */\r\nexport const detect = async (source, model, canvasRef, callback = () => {}) => {\r\n  const [modelWidth, modelHeight] = model.inputShape.slice(1, 3); // get model width and height\r\n\r\n  tf.engine().startScope(); // start scoping tf engine\r\n  const [input, xRatio, yRatio] = preprocess(source, modelWidth, modelHeight); // preprocess image\r\n\r\n  const res = model.net.execute(input); // inference model\r\n  const transRes = res.transpose([0, 2, 1]); // transpose result [b, det, n] => [b, n, det]\r\n  const boxes = tf.tidy(() => {\r\n    const w = transRes.slice([0, 0, 2], [-1, -1, 1]); // get width\r\n    const h = transRes.slice([0, 0, 3], [-1, -1, 1]); // get height\r\n    const x1 = tf.sub(transRes.slice([0, 0, 0], [-1, -1, 1]), tf.div(w, 2)); // x1\r\n    const y1 = tf.sub(transRes.slice([0, 0, 1], [-1, -1, 1]), tf.div(h, 2)); // y1\r\n    return tf\r\n      .concat(\r\n        [\r\n          y1,\r\n          x1,\r\n          tf.add(y1, h), //y2\r\n          tf.add(x1, w), //x2\r\n        ],\r\n        2\r\n      )\r\n      .squeeze();\r\n  }); // process boxes [y1, x1, y2, x2]\r\n\r\n  const [scores, classes] = tf.tidy(() => {\r\n    // class scores\r\n    const rawScores = transRes.slice([0, 0, 4], [-1, -1, numClass]).squeeze(0); // #6 only squeeze axis 0 to handle only 1 class models\r\n    return [rawScores.max(1), rawScores.argMax(1)];\r\n  }); // get max scores and classes index\r\n\r\n  const nms = await tf.image.nonMaxSuppressionAsync(boxes, scores, 500, 0.45, 0.2); // NMS to filter boxes\r\n\r\n  const boxes_data = boxes.gather(nms, 0).dataSync(); // indexing boxes by nms index\r\n  const scores_data = scores.gather(nms, 0).dataSync(); // indexing scores by nms index\r\n  const classes_data = classes.gather(nms, 0).dataSync(); // indexing classes by nms index\r\n\r\n  renderBoxes(canvasRef, boxes_data, scores_data, classes_data, [xRatio, yRatio]); // render boxes\r\n  tf.dispose([res, transRes, boxes, scores, classes, nms]); // clear memory\r\n\r\n  callback();\r\n\r\n  tf.engine().endScope(); // end of scoping\r\n};\r\n\r\n/**\r\n * Function to detect video from every source.\r\n * @param {HTMLVideoElement} vidSource video source\r\n * @param {tf.GraphModel} model loaded YOLOv8 tensorflow.js model\r\n * @param {HTMLCanvasElement} canvasRef canvas reference\r\n */\r\nexport const detectVideo = (vidSource, model, canvasRef) => {\r\n  /**\r\n   * Function to detect every frame from video\r\n   */\r\n  const detectFrame = async () => {\r\n    if (vidSource.videoWidth === 0 && vidSource.srcObject === null) {\r\n      const ctx = canvasRef.getContext(\"2d\");\r\n      ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height); // clean canvas\r\n      return; // handle if source is closed\r\n    }\r\n\r\n    detect(vidSource, model, canvasRef, () => {\r\n      requestAnimationFrame(detectFrame); // get another frame\r\n    });\r\n  };\r\n\r\n  detectFrame(); // initialize to detect every frame\r\n};\r\n"],"mappings":"AAAA,MAAO,GAAK,CAAAA,EAAE,KAAM,kBAAkB,CACtC,OAASC,WAAW,KAAQ,aAAa,CACzC,MAAO,CAAAC,MAAM,KAAM,eAAe,CAElC,KAAM,CAAAC,QAAQ,CAAGD,MAAM,CAACE,MAAM,CAE9B;AACA;AACA;AACA;AACA;AACA;AACA,GACA,KAAM,CAAAC,UAAU,CAAGA,CAACC,MAAM,CAAEC,UAAU,CAAEC,WAAW,GAAK,CACtD,GAAI,CAAAC,MAAM,CAAEC,MAAM,CAAE;AAEpB,KAAM,CAAAC,KAAK,CAAGX,EAAE,CAACY,IAAI,CAAC,IAAM,CAC1B,KAAM,CAAAC,GAAG,CAAGb,EAAE,CAACc,OAAO,CAACC,UAAU,CAACT,MAAM,CAAC,CAEzC;AACA,KAAM,CAACU,CAAC,CAAEC,CAAC,CAAC,CAAGJ,GAAG,CAACK,KAAK,CAACC,KAAK,CAAC,CAAC,CAAE,CAAC,CAAC,CAAE;AACtC,KAAM,CAAAC,OAAO,CAAGC,IAAI,CAACC,GAAG,CAACL,CAAC,CAAED,CAAC,CAAC,CAAE;AAChC,KAAM,CAAAO,SAAS,CAAGV,GAAG,CAACW,GAAG,CAAC,CACxB,CAAC,CAAC,CAAEJ,OAAO,CAAGJ,CAAC,CAAC,CAAE;AAClB,CAAC,CAAC,CAAEI,OAAO,CAAGH,CAAC,CAAC,CAAE;AAClB,CAAC,CAAC,CAAE,CAAC,CAAC,CACP,CAAC,CAEFR,MAAM,CAAGW,OAAO,CAAGH,CAAC,CAAE;AACtBP,MAAM,CAAGU,OAAO,CAAGJ,CAAC,CAAE;AAEtB,MAAO,CAAAhB,EAAE,CAACyB,KAAK,CACZC,cAAc,CAACH,SAAS,CAAE,CAAChB,UAAU,CAAEC,WAAW,CAAC,CAAE;AAAA,CACrDmB,GAAG,CAAC,KAAK,CAAE;AAAA,CACXC,UAAU,CAAC,CAAC,CAAC,CAAE;AACpB,CAAC,CAAC,CAEF,MAAO,CAACjB,KAAK,CAAEF,MAAM,CAAEC,MAAM,CAAC,CAChC,CAAC,CAED;AACA;AACA;AACA;AACA;AACA;AACA,GACA,MAAO,MAAM,CAAAmB,MAAM,CAAG,cAAAA,CAAOvB,MAAM,CAAEwB,KAAK,CAAEC,SAAS,CAA0B,IAAxB,CAAAC,QAAQ,CAAAC,SAAA,CAAA7B,MAAA,IAAA6B,SAAA,MAAAC,SAAA,CAAAD,SAAA,IAAG,IAAM,CAAC,CAAC,CACxE,KAAM,CAAC1B,UAAU,CAAEC,WAAW,CAAC,CAAGsB,KAAK,CAACK,UAAU,CAAChB,KAAK,CAAC,CAAC,CAAE,CAAC,CAAC,CAAE;AAEhEnB,EAAE,CAACoC,MAAM,CAAC,CAAC,CAACC,UAAU,CAAC,CAAC,CAAE;AAC1B,KAAM,CAAC1B,KAAK,CAAEF,MAAM,CAAEC,MAAM,CAAC,CAAGL,UAAU,CAACC,MAAM,CAAEC,UAAU,CAAEC,WAAW,CAAC,CAAE;AAE7E,KAAM,CAAA8B,GAAG,CAAGR,KAAK,CAACS,GAAG,CAACC,OAAO,CAAC7B,KAAK,CAAC,CAAE;AACtC,KAAM,CAAA8B,QAAQ,CAAGH,GAAG,CAACI,SAAS,CAAC,CAAC,CAAC,CAAE,CAAC,CAAE,CAAC,CAAC,CAAC,CAAE;AAC3C,KAAM,CAAAC,KAAK,CAAG3C,EAAE,CAACY,IAAI,CAAC,IAAM,CAC1B,KAAM,CAAAK,CAAC,CAAGwB,QAAQ,CAACtB,KAAK,CAAC,CAAC,CAAC,CAAE,CAAC,CAAE,CAAC,CAAC,CAAE,CAAC,CAAC,CAAC,CAAE,CAAC,CAAC,CAAE,CAAC,CAAC,CAAC,CAAE;AAClD,KAAM,CAAAH,CAAC,CAAGyB,QAAQ,CAACtB,KAAK,CAAC,CAAC,CAAC,CAAE,CAAC,CAAE,CAAC,CAAC,CAAE,CAAC,CAAC,CAAC,CAAE,CAAC,CAAC,CAAE,CAAC,CAAC,CAAC,CAAE;AAClD,KAAM,CAAAyB,EAAE,CAAG5C,EAAE,CAAC6C,GAAG,CAACJ,QAAQ,CAACtB,KAAK,CAAC,CAAC,CAAC,CAAE,CAAC,CAAE,CAAC,CAAC,CAAE,CAAC,CAAC,CAAC,CAAE,CAAC,CAAC,CAAE,CAAC,CAAC,CAAC,CAAEnB,EAAE,CAAC2B,GAAG,CAACV,CAAC,CAAE,CAAC,CAAC,CAAC,CAAE;AACzE,KAAM,CAAA6B,EAAE,CAAG9C,EAAE,CAAC6C,GAAG,CAACJ,QAAQ,CAACtB,KAAK,CAAC,CAAC,CAAC,CAAE,CAAC,CAAE,CAAC,CAAC,CAAE,CAAC,CAAC,CAAC,CAAE,CAAC,CAAC,CAAE,CAAC,CAAC,CAAC,CAAEnB,EAAE,CAAC2B,GAAG,CAACX,CAAC,CAAE,CAAC,CAAC,CAAC,CAAE;AACzE,MAAO,CAAAhB,EAAE,CACN+C,MAAM,CACL,CACED,EAAE,CACFF,EAAE,CACF5C,EAAE,CAACgD,GAAG,CAACF,EAAE,CAAE9B,CAAC,CAAC,CAAE;AACfhB,EAAE,CAACgD,GAAG,CAACJ,EAAE,CAAE3B,CAAC,CAAG;AAAA,CAChB,CACD,CACF,CAAC,CACAgC,OAAO,CAAC,CAAC,CACd,CAAC,CAAC,CAAE;AAEJ,KAAM,CAACC,MAAM,CAAEC,OAAO,CAAC,CAAGnD,EAAE,CAACY,IAAI,CAAC,IAAM,CACtC;AACA,KAAM,CAAAwC,SAAS,CAAGX,QAAQ,CAACtB,KAAK,CAAC,CAAC,CAAC,CAAE,CAAC,CAAE,CAAC,CAAC,CAAE,CAAC,CAAC,CAAC,CAAE,CAAC,CAAC,CAAEhB,QAAQ,CAAC,CAAC,CAAC8C,OAAO,CAAC,CAAC,CAAC,CAAE;AAC5E,MAAO,CAACG,SAAS,CAAC9B,GAAG,CAAC,CAAC,CAAC,CAAE8B,SAAS,CAACC,MAAM,CAAC,CAAC,CAAC,CAAC,CAChD,CAAC,CAAC,CAAE;AAEJ,KAAM,CAAAC,GAAG,CAAG,KAAM,CAAAtD,EAAE,CAACyB,KAAK,CAAC8B,sBAAsB,CAACZ,KAAK,CAAEO,MAAM,CAAE,GAAG,CAAE,IAAI,CAAE,GAAG,CAAC,CAAE;AAElF,KAAM,CAAAM,UAAU,CAAGb,KAAK,CAACc,MAAM,CAACH,GAAG,CAAE,CAAC,CAAC,CAACI,QAAQ,CAAC,CAAC,CAAE;AACpD,KAAM,CAAAC,WAAW,CAAGT,MAAM,CAACO,MAAM,CAACH,GAAG,CAAE,CAAC,CAAC,CAACI,QAAQ,CAAC,CAAC,CAAE;AACtD,KAAM,CAAAE,YAAY,CAAGT,OAAO,CAACM,MAAM,CAACH,GAAG,CAAE,CAAC,CAAC,CAACI,QAAQ,CAAC,CAAC,CAAE;AAExDzD,WAAW,CAAC8B,SAAS,CAAEyB,UAAU,CAAEG,WAAW,CAAEC,YAAY,CAAE,CAACnD,MAAM,CAAEC,MAAM,CAAC,CAAC,CAAE;AACjFV,EAAE,CAAC6D,OAAO,CAAC,CAACvB,GAAG,CAAEG,QAAQ,CAAEE,KAAK,CAAEO,MAAM,CAAEC,OAAO,CAAEG,GAAG,CAAC,CAAC,CAAE;AAE1DtB,QAAQ,CAAC,CAAC,CAEVhC,EAAE,CAACoC,MAAM,CAAC,CAAC,CAAC0B,QAAQ,CAAC,CAAC,CAAE;AAC1B,CAAC,CAED;AACA;AACA;AACA;AACA;AACA,GACA,MAAO,MAAM,CAAAC,WAAW,CAAGA,CAACC,SAAS,CAAElC,KAAK,CAAEC,SAAS,GAAK,CAC1D;AACF;AACA,KACE,KAAM,CAAAkC,WAAW,CAAG,KAAAA,CAAA,GAAY,CAC9B,GAAID,SAAS,CAACE,UAAU,GAAK,CAAC,EAAIF,SAAS,CAACG,SAAS,GAAK,IAAI,CAAE,CAC9D,KAAM,CAAAC,GAAG,CAAGrC,SAAS,CAACsC,UAAU,CAAC,IAAI,CAAC,CACtCD,GAAG,CAACE,SAAS,CAAC,CAAC,CAAE,CAAC,CAAEF,GAAG,CAACG,MAAM,CAACC,KAAK,CAAEJ,GAAG,CAACG,MAAM,CAACE,MAAM,CAAC,CAAE;AAC1D,OAAQ;AACV,CAEA5C,MAAM,CAACmC,SAAS,CAAElC,KAAK,CAAEC,SAAS,CAAE,IAAM,CACxC2C,qBAAqB,CAACT,WAAW,CAAC,CAAE;AACtC,CAAC,CAAC,CACJ,CAAC,CAEDA,WAAW,CAAC,CAAC,CAAE;AACjB,CAAC"},"metadata":{},"sourceType":"module","externalDependencies":[]}